%!TEX root = ../main.tex

\chapter{Einleitung} \label{Einleitung}

%----------------------------------------------------------------------------------------

%Define math commands used in this thesis
	% G E N E R A L
	\newcommand{\R}{\mathbb{R}}  % Symbol for real numbers
	\newcommand{\seqx}{\{\mathbf{x}_i\}_{i=1}^N, \ (\mathbf{x}_i \in \mathbb{R}^D)}  % Sequence of x_i
	\newcommand{\seq}[1][\mathbf{x}]{\{{#1}_i\}_{i=1}^N, \ ({#1}_i \in \mathbb{R}^D)}  % Sequence of input
	\providecommand{\abs}[1]{\lvert#1\rvert}  % produces | x |
	\providecommand{\norm}[1]{\lVert#1\rVert}  % produces || x ||

	% C H A P T E R 2
	\renewcommand{\C}{\mathscr{C}}  % Symbol for a category C
	\newcommand{\D}{\mathscr{D}}  % Symbol for a category D
	\renewcommand{\N}{\mathbb{N}}  % Symbol for natural numbers
	\newcommand{\M}{\mathcal{M}}  % Symbol for Manifold M
	\newcommand{\cech}{\u{C}ech}  % Symbol for Cech complex
	\newcommand{\Set}{\mathbf{Set}}  % Symbol for category of sets
	\newcommand{\sSet}{\mathbf{sSet}}  % Symbol for category of sets
	\newcommand{\Top}{\mathbf{Top}}  % Symbol for category of sets
	\newcommand{\Fuzz}{\mathbf{Fuzz}}  % Symbol for fuzzy set category
	\newcommand{\sFuzz}{\mathbf{sFuzz}}  % Symbol for fuzzy set category
	\newcommand{\EPMet}{\mathbf{EPMet}}  % Symbol for category of extended pseudo metric spaces
	\renewcommand{\hom}{\mathsf{Hom}}  % Symbol for morphisms
	\newcommand{\fReal}{\mathsf{FinReal}}  % Symbol for Real functor
	\newcommand{\fSing}{\mathsf{FinSing}}  % Symbol for Sing functor
	\newcommand{\fsFuzz}{\mathbf{Fin\text{-}sFuzz}}  % Symbol for finite fuzzy set category
	\newcommand{\fEPMet}{\mathbf{Fin\text{-}EPMet}}  % Symbol for category of finite extended pseudo metric spaces
	\newcommand*{\Scale}[2][4]{\scalebox{#1}{\ensuremath{#2}}}
	\newcommand{\tConorm}{\Scale[1.5]{\bot}^N_{i=1}}  % Symbol for t-Conorm
	% Alternatives for t-Conorms: $\bot_{\{1 \leq i \leq N\}}$ $\underset{i=1}{\overset{N}{\bot}}$ $\bot^N_{i=1}$

	% C H A P T E R 3
	\newcommand{\Yrep}{\mathcal{Y}}  % Symbol for a low dimensional topological representation
	\newcommand{\Xrep}{\mathcal{X}}  % Symbol for a high dimensional topological representation

	% C H A P T E R 4
	\newcommand{\indexij}[1][v]{{#1}_{ij}}  % Symbol for inp_{ij}
	\newcommand{\vij}{v_{ij}}  % Symbol for b_{ij}
	\newcommand{\wij}{w_{ij}}  % Symbol for w_{ij}
	\newcommand{\deriv}[2]{\frac{\partial {#1}}{\partial {#2}}}
	\newcommand{\sumtup}[2]{\sum_{{#1},{#2} = 1}^N}
	\newcommand{\sumtups}[1]{\sum_{{#1} = 1}^N}
	\newcommand{\Xg}{\mathcal{X}_G}  % Symbol for Graph of \Xrep
	\newcommand{\Xgi}{\mathcal{X}_{{G}_i}}  % Symbol for Graph of \Xrep
	\newcommand{\wX}{w_\mathcal{X}}  % Symbol for weights of \Xrep
	\newcommand{\WX}{W_\mathcal{X}}  % Symbol for Graph of \Xrep
	\newcommand{\wY}{w_\mathcal{Y}}  % Symbol for weights of \Yrep
	\newcommand{\Yg}{\mathcal{Y}_G}  % Symbol for Graph of \Xrep
	\newcommand{\xxi}{\mathbf{x}_i}
	\newcommand{\xxj}{\mathbf{x}_j}
	\newcommand{\xij}{\mathbf{x}_{i_j}}
	\newcommand{\wXi}{w_{\mathcal{X}_i}}  % Symbol for weights of \Xrep
	\newcommand{\yyi}{\mathbf{y}_i}
	\newcommand{\yyj}{\mathbf{y}_j}

%----------------------------------------------------------------------------------------

% N O T I Z E N
	% Zu unterscheiden zwischen Informations visualisierung und ML DR Algs
	% (siehe https://perso.uclouvain.be/michel.verleysen/papers/iconip13mv.pdf)

	% T E X T B A U S T E I N E
	% 'UMAP wird für single cell RNA-sequencing genutzt'
	% scRNA hat mehr rauschen als bulkRNA-seq und wird zur Untersuchung der genetischen 
	% Information (Genexpression) einzelner Zellen genutzt.
	% 'Dimension ist Anzahl der Freiheitsgerade'
	% Es gibt Fälle in denen es unmöglich ist die gesamte globale Struktur zu erhalten. 
	% Betrachet man beispielsweise gleichverteilte Punkte auf einem Kreis und möchte diese 
	% in R einbetten, muss es zwei Punkte geben welche getrennt werden.

	% Sehr anschauliches Beispiel für die Größe des Raums, siehe \cite{Lawrence}, wenn man 
	% eine Zahl nimmt und jede Nanosekunde ein Beispiel betrachtet würde man 'nie' die 
	% ursprüngliche 6 sehen.

	% DR zum Aufstellen von Thesen, zb in der Genetik
	% Wenige unterschiede zwischen UMAP und tSNE
	% https://www.biorxiv.org/content/biorxiv/early/2018/09/23/423632.full.pdf

	% Beim single-cell RNA-sequencing D=20000  siehe 4
	% Zell Populationen sind Cluster

	% PCA Overcrowding, da nur linear

	% Einordnung verschiedener DR Algorithmen. (Geometrie, Stochastik, Topologie)
	% Was ist eine gute Repräsentation der Daten?
	% Sollte unabhängig von Transformationen weniger wichtiger Eigenschaften sein und 
	% unterscheidbar bzgl. relevanter Eigenschaften. (evtl. Bengio zitieren)
	% Früher 'feature engineering' jetzt lernen der wichtigen Eigenschaften (siehe Bengio 2013)
	% Welche Formen von Datenanalyse (statistische, geometrische,...)

	% TODO: Betrachte Oudot s.67
	% TODO: Anwendungen von persistence Oudot s.8
	% TODO: ergänzend siehe Oudot, Ch.4

%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------

%\section{Einleitung}
	Wer heutzutage eine Zeitung aufschlägt wird mit hoher Wahrscheinlichkeit kontroverse 
	Artikel über künstliche Intelligenz, Machine Learning, Deep Learning oder Big Data finden. 
	Diese Themen haben nicht nur Relevanz und Auswirkungen für große Konzerne wie Google, 
	Facebook oder Amazon, sondern auch für unser alltägliches privates Leben.
	Jeden Tag werden neue Daten erzeugt und damit die Suche nach effizienten Algorithmen, 
	die mit großen Datenbeständen umgehen können, wichtiger. Algorithmen helfen Muster in 
	vorhandenen Datenbeständen zu erkennen, Vorhersagen zu treffen oder Daten zu klassifizieren. 
	Mit mathematischen Modellen können neue Erkenntnisse auf Grundlage dieser Muster gewonnen werden. 
	Ziel ist es also, große Datenmengen in Informationen und diese Informationen in Erkenntnisse zu überführen.
	Die Aufgabe, effiziente Verfahren zur Datenanalyse zu entwerfen, ist somit von hoher Relevanz. 

	Um einen Überblick der Aufgabenbereiche der Datenanalyse zu erhalten kann man diese in drei Felder 
	unterteilen \cite{wirt}.
	Die \textit{deskriptive} Datenanalyse beschreibt Daten, beispielsweise durch graphische Visualisierung. 
	Damit ist sie verbunden mit der \textit{explorativen} Datenanalyse. Diese 
	dient zum Entdecken neuer Zusammenhänge, oft werden dazu graphische Methoden genutzt. 
	Die \textit{inferenzielle} Datenanalyse nutzt gegebene Stichproben, um auf nicht erhobene Stichproben 
	zu schließen. Dieser Bereich hat in den vergangenen Jahren stark an Bedeutung gewonnen, 
	insbesondere aufgrund der sehr guten Resultate, die durch neuronale Netzwerke erzielt wurden. 

	In dieser Arbeit möchten wir uns mit \textit{Verfahren zur Dimensionsreduktion} beschäftigen. 
	Diese dienen der deskriptiven und der explorativen Datenanalyse. Zusätzlich 
	lassen sie sich dazu nutzen, Verfahren zur inferenziellen Datenanalyse zu verbessern. 
	Wir werden etwas später auf die Anwendungen zurückkommen. Doch zuerst möchten wir 
	die Problemstellung formulieren. 

\subsection*{Dimensionsreduktion}
	Sei $X$ eine Menge an Daten. Dabei betrachten wir von nun an Daten, welche uns in Form von 
	$D$-dimensionalen reellen Vektoren gegeben sind. Somit ergibt sich für $N$ Datenpunkte 
	$X = \{\xxi\}_{1 \leq i \leq N}$ mit $\xxi \in \R^D$. 
	Wenn $D > 10$ sprechen wir meist von \textit{hochdimensionalen Daten}.
	Dabei ist die Beschränkung auf Daten sinnvoll, welche sich als Vektoren beschreiben lassen,  
	da uns die Darstellung die mathematische Formulierung des Problems erleichtert. 
	Außerdem können sehr verschiedene Daten in dieser Form angegeben werden. 
	So kann man ein digitales Bild als Vektor auffassen, indem die Dimension der Anzahl 
	an Pixeln entspricht und die Farbwerte der Pixel die Einträge der Vektoren bestimmen. 
	Wörter können ebenfalls als Vektor angegeben werden, indem beispielsweise die Dimension der 
	Gesamtzahl der Wörter entspricht und die Wörter durch Einheitsvektoren darstellt werden. 
	Wir sehen, dass die Anzahl an Dimensionen sehr groß werden kann. Eine moderne Kamera 
	macht Bilder mit meist mehr als $1920 \times 1080$ Pixeln, dies entspricht $D = \num{2073600}$. 
	Die deutsche Sprache hat circa 23 Millionen unterschiedliche Wörter, somit wäre $D = \num{23000000}$. 
	
	Wir sprechen von einer \textit{Dimensionsreduktion} von $X$, wenn wir eine \textit{Einbettung} $Y$ angeben, 
	mit $Y = \{\yyi\}_{1 \leq i \leq N}$ und $\yyi \in \R^d$, wobei $d \ll D$, so dass 
	sich $X$ und $Y$ \textit{ähnlich} sind. 

	Nun möchten wir zurück auf die Ziele der Datenanalyse kommen. Die Einbettung $Y$ kann dazu 
	dienen, die Daten $X$ zu visualisieren, wenn $d \in {1,2,3}$. Da $X$ und $Y$ ähnlich sind, 
	können durch die Visualisierung von $Y$ Rückschlüsse auf $X$ gemacht werden. Oft lassen sich 
	in der Visualisierung sogenannte Cluster erkennen, siehe dazu Abbildung \ref{fig:umap_mnist}. 
	Neben der Visualisierung kann die Einbettung $Y$ zur Vorverarbeitung genutzt werden, also als 
	Eingabe für einen anderen Algorithmus der Datenanalyse. So werden Dimensionsreduktionen 
	beispielsweise in Algorithmen für Gesichtserkennung genutzt. 
	Die Einbettung von $X$ benötigt zudem aufgrund der deutlich kleineren Dimension weniger physischen 
	Speicherplatz. Dieser Aspekt ist zwar nicht entscheidend für die Datenanalyse, dennoch erwähnenswert, 
	insbesondere dann, wenn nur begrenzt viel Speicher zur Verfügung steht. 

	\begin{figure}
		\centering
		\includegraphics[width=200px, height=200px]{Figures/umap_mnist}
		%\decoRule
		\caption[UMAP auf MNIST]{Einbettung von Bildern mit $D = 784, N=\num{70000}$ (MNIST Datensatz). Die Farben markieren unterschiedliche 
								Ziffern von $0$ bis $9$. Eine genauere Beschreibung findet sich in Kapitel \ref{Experimente}.}
		\label{fig:umap_mnist}
	\end{figure}

	Eine häufig getroffene Annahme ist, dass die Daten $X$ auf einer niedrigdimensionalen 
	Struktur liegen. In der Literatur ist diese Annahme als Mannigfaltigkeit-Hypothese 
	(\textit{engl.: manifold hypothesis}) bekannt \cite{Mitter,Rifai}. Dabei kann eine 
	Mannigfaltigkeit als Raum betrachtet werden, welcher lokal einem niedrigdimensionalen Raum gleicht. 
	So ist beispielsweise der Erdball eine $2$-dimensionale Mannigfaltigkeit, da sie lokal gesehen 
	flach ist. Intuitiv wird diese Annahme dadurch gerechtfertigt, dass wir Daten messen, 
	welche nicht relevant sind. Beispielsweise ist der Hintergrund eines Bildes von einem Gesicht 
	bei der Gesichtserkennung nicht relevant. 

	Wir müssen nun den Begriff der \textit{Ähnlichkeit} von $X$ und $Y$ präzisieren und angeben,  
	wie wir $Y$ systematisch finden können. 
	Dabei lässt sich die Frage nach der \textit{Ähnlichkeit} mathematisch unterschiedlich formulieren. 
	Wir verweisen den Leser auf \cite{Lee2009,Rieck2015}. 

\subsection*{Verfahren zur Dimensionsreduktion}
	Um für hochdimensionale Daten $X$ eine niedrigdimensionale Einbettung zu finden, wendet 
	man \textit{Dimensionsreduktionsverfahren} (kurz: \textit{DR Verfahren}) an. 
	Dabei gibt es DR Verfahren, welche bei der Einbettung globale Distanzen bevorzugen. 
	Bekannte Verfahren dabei sind PCA, MDS und Sammon Mapping. Zu den Verfahren, welche 
	die lokalen Distanzen bevorzugen, gehören Isomap, Laplacian Eigenmaps und t-SNE. 
	Die Begriffe \textit{lokal} und \textit{global} sind dabei nicht fest definiert. 
	Wir werden später genauer auf einige Verfahren eingehen. 

\subsection*{UMAP}
	Der Fokus dieser Arbeit liegt auf der Darstellung und Analyse des UMAP Verfahrens \cite{UMAP}. 
	UMAP ist ein Verfahren zur Dimensionsreduktion und kommt aus dem Bereich der 
	\textit{topologischen Datenanalyse}, diese nutzt mathematische Instrumente der Topologie 
	um Daten zu beschreiben. 
	Das Verfahren nimmt die Mannigfaltigkeit-Hypothese an. Im ersten Schritt des Verfahrens 
	betrachtet man von jedem Datenpunkt die Distanz zu seinen benachbarten Punkten und nutzt diese 
	zusammen mit einer Aussage der Riemannschen Geometrie, um lokale Distanzen auf der Mannigfaltigkeit 
	zwischen den Datenpunkten zu bestimmen. Diese Konstruktion liefert uns für jeden Datenpunkt 
	einen \textit{metrischen Raum}, wobei die \textit{Metriken} zwischen den Räumen a priori 
	nicht miteinander kompatibel sind. Um dieses Problem zu lösen werden wir für jeden metrischen Raum eine 
	\textit{unscharfe simpliziale Menge} konstruieren, welche die wichtigen Informationen des 
	metrischen Raumes enthält. Die simplizialen Mengen können wir miteinander vereinigen. Ähnlich konstruieren wir 
	für eine initiale Einbettung $Y$ eine zugehörige simpliziale Menge. Wir werden dann einen Abstandsbegriff 
	zwischen den simplizialen Mengen nutzen, um die Darstellung von $Y$ zu optimieren. 

\subsection*{Eigene Beiträge}
	Wir möchten an dieser Stelle darauf hinweisen, dass sich die Darstellung der Theorie des UMAP Verfahrens 
	nach der ursprünglichen Veröffentlichung von McInnes et. al. \cite{UMAP} richtet. Allerdings 
	wurde diese an vielen Stellen durch anschauliche Erklärungen und Intuitionen ergänzt. 
	Die von uns gemachten Beiträge sind dabei, 

	\begin{itemize}
		\item eine übersichtliche Zusammenfassung der für das UMAP Verfahren wichtigen Definitionen 
			  und Sätze mit intuitiven Erläuterungen,  
		\item eine ausführliche Darstellung des UMAP Verfahrens, 
		\item eine Betrachtung der rechenintensiven Schritte der Implementierung und alternative Methoden für diese, 
		\item eine Anwendung des UMAP Verfahrens auf einen neuen komplexen Datensatz, 
		\item Ansätze für weitere Betrachtungen zur Verbesserung des UMAP Verfahrens.
	\end{itemize}

\subsection*{Aufbau der Arbeit}
	In Kapitel \ref{Grundlagen} werden wir die für das UMAP Verfahren benötigten Definitionen und Sätze angeben. 
	Dabei werden wir zuerst auf den Begriff der riemannschen Mannigfaltigkeit hinarbeiten, welcher aufgrund 
	der Mannigfaltigkeit-Hypothese die Grundlage für weitere Überlegungen legt. Dann werden \textit{Kategorien} 
	und wichtige Aussagen der Kategorientheorie vorgestellt. Mithilfe von Kategorien können wir dann \textit{simpliziale Mengen} 
	einführen, welche die Grundlage für die Repräsentation der Daten legen. Diesen Begriff werden wir auf 
	\text{unscharfe} simpliziale Mengen erweitern. 

	Die Aussagen werden uns in Kapitel \ref{UMAP} helfen, die Theorie des UMAP Verfahrens darzustellen. 
	Diese soll in drei Schritten beschrieben werden. Zuerst werden wir die Mannigfaltigkeit approximieren und 
	eine Familie metrischer Räume konstruieren. Danach werden wir diese metrischen Räume in unscharfe simpliziale 
	Mengen umwandeln. Dies wird uns eine Repräsentation $\Xrep$ der Daten $X$ liefern. Zuletzt werden wir eine ähnliche 
	Repräsentation $\Yrep$ für $Y$ konstruieren und beschrieben, wie die Repräsentation $\Yrep$ optimiert werden kann, 
	damit sie $\Xrep$ möglichst ähnlich ist. Das bezüglich $\Xrep$ optimierte $\Yrep$ kann dann mittels der eingeführten 
	Theorie als metrischer Raum dargestellt werden, der uns die Einbettung von $X$ liefert. 

	Kapitel \ref{Implementierung} wird einen Fokus auf die Implementierung des UMAP Verfahren legen. Zunächst soll 
	die UMAP Theorie angepasst werden, um eine effiziente Implementierung zu ermöglichen. Wir werden dann eine 
	Implementierung \cite{cpu} betrachten und die rechenintensiven Subroutinen angeben. Weitere Überlegungen sollen 
	Alternativen beschreiben. Wir werden diese Kapitel mit einer Übersicht der Hyperparameter des UMAP Verfahrens 
	abschließen. 

	Das UMAP Verfahren soll in Kapitel \ref{Experimente} mit zwei verwandten Verfahren auf unterschiedlichen 
	Datensätzen analysiert werden. Dazu werden wir eine kurze Beschreibung des t-SNE und TriMap Verfahren geben. 
	Mit diesen drei Verfahren werden wir einen Datensatz mit Cartoon Gesichtern analysieren. Diese Analyse soll 
	testen, wie gut die Einbettungen der Verfahren sind. Zusätzlich sollen die Verfahren auf dem bekannten 
	MNIST Datensatz getestet werden. 

	Die Resultate dieser Arbeit werden in Kapitel \ref{Zusammenfassung} zusammengefasst. 
	Außerdem formulieren wir in diesem Kapitel Ansätze, um das UMAP Verfahren zu verbessern. 

%----------------------------------------------------------------------------------------