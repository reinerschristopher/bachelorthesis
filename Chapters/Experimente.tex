%!TEX root = ../main.tex

\chapter{Experimente} 

\label{Experimente}

%----------------------------------------------------------------------------------------

% A U F B A U
% Welche Verfahren
% Welche Daten
% Welche Ergebnisse unter welchen Parametern
% Welche Laufzeit
% Welche Schlussfolgerungen

% N O T I Z E N
% Cartoonset, MNIST, (WIND)
% PCA, UMAP, t-SNE, LargeVis

% Test transform function

% Google News für n_samples Dimension

% Outlier, add completly different images 

% Erwähne analytische Bewertungen der Einbettungen
% trustworthiness-continuity (Kaski et al., 2003)
% mean (smoothed) precision-recall (Venna et al., 2010)
% nearest-neighbor accuracy (Van Der Maaten et al., 2009)

% Stabilität der Ergebnisse

% Komplett neue Gesichter

% Cluster on FMNIST, Scores on MNIST (Costfunction and SVD)

% CUDA tSNE
% https://github.com/CannyLab/tsne-cuda
% https://arxiv.org/abs/1807.11824s

% T E X T B A U S T E I N E
% 'Empirisches testen der Hypothesen/ Annahmen'
% 'UMAP auf realen/echten Daten'
% In \cite{UMAP} wurde bereits die Stabilität des Verfahrens getestet.
% Insbesondere verweisen wir auf Abbildung 3,4 in Abschnitt 5.
% Die Stabilität des UMAP Verfahrens ist 

% Mehr Datenpunkte, dann höhere perplexität für gleichen Ausgang, ähnlich zu n_neighbor
% tSNE vergrößert Regionen mit höherer Dichte

% Bei cartoonpca784 bleibt 99,842% der Varianz erhalten.
% Bei cartoonpca10k weniger als 10^-5 * 2 verlust der Varianz 

% Um eine gute Interpretation der Daten zu geben ist es wichtig ein sehr gutes Verständnis 
% der Datensätze zu besitzen, deshalb haben wir uns auf leicht interpretierbare Daten beschränkt

% Verweise auf Daten und erwähne deutlich feinere Struktur von UMAP
% https://www.biorxiv.org/content/biorxiv/early/2018/04/10/298430.full.pdf

% Keine Wordembeddings, da die Vorvererbeitung sehr wichtig ist.

%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------

% \section{Einleitung}
	Nach ausführlicher Darstellung der Theorie des UMAP Verfahrens, möchten wir nun UMAP auf 
	drei Datensätzen mit alternativen Verfahren empirisch testen.
	Wir werden eine möglichst vollständige Darstellung der Ergebnisse in dieser Arbeit präsentieren. 
	Allerdings ist es zu empfehlen die Ergebnisse in einem interaktiven Jupyter notebook zu betrachten. 
	Dieses befindet sich auf der beigelegten CD oder auf GitHub
	\footnote{\url{https://github.com/reinerschristopher/bachelorthesis}}. %TODO: korrigiere link

%----------------------------------------------------------------------------------------

\section{Alternative Verfahren}
	% TODO: Liste mit t-SNE, Fit-SNE, PCA, ISOMAP, LargeVis. 
	% Kurz was macht das verfahren aus; Link; wichtige Hyperparameter
	Wir haben uns dazu entschieden UMAP mit folgenden Verfahren zu vergleichen:


	Da die Implementierungen des Laplacian Eigenmaps Verfahrens und Isomap Verfahrens schlecht für große 
	Datensätze skalieren, haben wir uns bewusst dazu entschieden, diese nicht mit in die Analyse aufzunehmen. 

%-----------------------------------

	\subsection{t-SNE}
	% TODO: wichtige Terme einfügen?
	Das t-SNE Verfahren \cite{tSNE} ist zur Zeit eines der bekanntesten und meistgenutzten 
	nicht-linearen Dimensionsreduktionsverfahren. Dabei wird UMAP fast ausschließlich 
	zur Visualisierung genutzt, da die Laufzeit für höhere Einbettungsdimensionen schlecht ist. 
	% TODO: Wie wir später sehen werden. (oder unten?)

	t-SNE konstruiert zuerst eine Wahrscheinlichkeitsverteilung $P$ auf Paaren $(i, j)$ der hochdimensionalen 
	Datenpunkten. Diese ist so gewählt, dass Paare ähnlicher Objekte eine höhere Wahrscheinlichkeit 
	zugeordnet bekommen, wohingegen sehr unterschiedliche Datenpunkte eine Wahrscheinlichkeit nahe $0$ haben. 
	Die Ähnlichkeit der Punkte wird dabei meist mittels der euklidischen Distanz gemessen, 
	kann aber ähnlich wie im UMAP Algorithmus durch andere Metriken ersetzt werden. Um $P$ zu konstruieren 
	wird eine Gaußverteilung genutzt, wobei die Varianz abhängig vom \code{perplexity} Parameter ist. 
	Die so erhaltenen Wahrscheinlichkeiten $p_{i | j}$ sind im Allgemeinen nicht symmetrisch. 
	Die Symmetrie wird durch mitteln der Daten erhalten. 

	Ähnlich wird eine Wahrscheinlichkeitsverteilung $Q$ im niedrigdimensionalen Raum mithilfe der 
	studentschen t-Verteilung konstruiert. Ursprünglich wurde $Q$ ebenfalls durch eine Gausverteilung 
	konstruiert, das so erhaltene Verfahren (SNE \cite{tSNEvar1}) ist allerdings aufgrund einer 
	schwierig zu optimierenden Zielfunktion und dem \enquote{crowding problem} wenig praktikabel.

	Um die d-dimensionale Repräsentation der Daten zu optimieren wir die Kullback-Leiber Divergenz 
	von zwischen $P$ und $Q$ bezüglich der $y_i$ minimiert. % TODO: werden y_i in Einleitung erwähnt?

	Seit der Veröffentlichung des Verfahrens wurden zahlreiche Verbesserungen, 
	insbesondere für die Laufzeit, vorgeschlagen \cite{tSNEmod1,tSNEmod3}. %TODO: zwei weitere Erweiterungen/Verbesserungen
	Dabei ist besonders Barnes-Hut-SNE \cite{tSNEmod2} zu erwähnen, allerdings sollte hier beachtet werden, 
	dass aufgrund der Konstruktion einer speziellen Datenstruktur die Laufzeit für $d>3$ sehr schlecht ist.


	Die von t-SNE produzierte Repräsentation der Daten ist vom \code{perplexity} Parameter abhängig. 
	Dabei kann man festhalten, je größer die \code{perplexity} ist, desto größer ist die Varianz  % TODO: Verweise auf die Gleichungen oben 
	des Gaußverteilung. Somit werden für große \code{perplexity} Werte globalere Strukturen erfasst, 
	da der Gaußkern sehr breit ist. Wenn der \code{perplexity} Parameter in der Größenordnung der 
	Anzahl an Datenpunkten $N$ liegt gleicht t-SNE dem MDS Verfahren. % TODO: Referenz? 

	Der zweite wichtige Hyperparameter, welchen wir beschreiben möchten ist die \code{exaggeration}.
	meistens wird hier zwischen \code{early-} und \code{late-exaggeration} unterschieden. 
	Im wesentlichen verbessert der Parameter die Optimierung des Gradienten und sorgt dafür, 
	dass Punkte desselben Clusters möglichst schnell in der niedrigdimensionalen Repräsentation 
	gruppiert werden \cite{tSNEcluster}. Der \code{late-exaggeration} wie in \cite{tSNEmod3} 
	beschrieben kontrahiert gefundene Cluster, so lassen sich in einer 2- oder 3-dimensionalen 
	Darstellung leichter Cluster bestimmen - entweder visuell oder mittels Clustering-Verfahren. 

	Wir werden reale Datensätze analysieren und das Verhalten der Hyperparameter beschreiben, um 
	ein zusätzliches Verständnis für die von t-SNE genutzten Hyperparameter zu bekommen 
	empfiehlt sich \cite{tSNEparam} - zeigt interaktiv auf künstlich erzeugten Datensätzen 
	die Auswirkung der Parameter.


	Für unsere Experimente haben wir die scikit Implementierung des t-SNE Verfahren genutzt \cite{scikit-learn}.
	Zusätzlich haben wir die openTSNE \cite{opentSNE} Implementierung genutzt. Diese beschleunigt 
	die Laufzeit des t-SNE Algorithmus durch eine zusätzliche Fouriertransformation \cite{tSNEmod3}.
	Die openTSNE Implementierung besitzt im Vergleich zur scikit Implementierung die Möglichkeit 
	den \code{late-exaggeration} Parameter zu spezifizieren. % TODO: später sehen wir die 

%-----------------------------------

	\subsection{TriMap}
	Das TriMap Verfahren \cite{TriMap} soll eine globalere Repräsentation der Daten finden als 
	beispielsweise t-SNE, das nicht nur paarweise die Ähnlichkeit zweier Objekte $i, j$ betrachtet wird, 
	sondern stets Triple $i, j, k$. Die so erhaltene globale Struktur der Daten soll die 
	Cluster-Abstände der Daten repräsentieren. 



	Wir haben diesem Algorithmus gewühlt, da die Tripletts Ähnlichkeiten mit 2-Simplizes des UMAP Verfahren haben.
	Die Tripletts sind vergleichbar mit den 2-Simplizes des UMAP Verfahrens. 
	Insbesondere können die Ansätze eine lineare Teilmenge ($O(N)$) an Tripletts zu finden 
	weitere Entwicklungen des UMAP Verfahren motivieren.

%----------------------------------------------------------------------------------------

\section{Bewertung der Ergebnisse}
	Um die $d$-dimensionalen Repräsentationen der Daten zu bewerten gibt es verschiedene Ansätze. 
	Diese sollen nun vorgestellt und verglichen werden. 


	Ein DR-Verfahren, welches die statistischen Eigenschaften der zugrundeliegenden Daten erfasst, 
	sollte invariant bezüglich Rauschen der Daten sein. Hingegen sollte eine schlechte Einbettung 
	wenig stabil sein, wenn zusätzliches Rauschen in den Daten auftritt. 

	Eine weitere Methodik um die Qualität der Einbettung zu erfassen, erhält man dadurch, 
	dass  

	In \cite{Harmeling} werden zwei Methoden zur Auswahl eines geeigneten DR-Verfahrens verglichen. 
	

	Um die lokale Qualität der Algorithmen zu analysieren haben wir uns die \textit{Cluster} in der 
	$2$-dimensionalen Repräsentation angeschaut, wobei wir als Cluster eine Teilmenge der Daten bezeichnen, 
	welche deutlich von den anderen Datenpunkten getrennt ist. % TODO: 'Stetigkeit' innerhalb der Cluster?
	Insbesondere bei der Analyse des Cartoon Set \ref{cartoonset} konnten wir gut lokale Strukturen 
	erkennen, da jeder Datenpunkt mehrere Eigenschaften gegeben hat -- im Vergleich zum MNIST und FMNIST 
	Datensatz, wo uns nur ein \textit{Label} pro Datenpunkt gegeben ist. 

	Die globale Struktur der Repräsentation qualitativ zu bewerten ist subjektiv. Dabei ist insbesondere 
	die Frage -- \enquote{Wie \textit{stark} unterscheiden sich die Cluster?} -- zu beantworten. 
	Beispielsweise sollten die Cluster welche die Ziffern 1 und 7 darstellen näher zueinander liegen als 
	die Cluster der Ziffern 1 und 6. 

	Für die qualitative Analyse wird die Fähigkeit des Gehirns genutzt Strukturen zu erkennen. 
	Nachteile der qualitativen Analyse sind, (1) die Subjektivität und somit Abhängigkeit vom Betrachter, 
	(2) dass sie nur im $d$-dimensionalen $(d \leq 3)$ möglich ist. 
	% und (3) die Problematik, dass es (noch) keine mathematische Formulierung der Bewertung gibt.

	In den folgenden Experimenten haben wir uns auf eine qualitative Analyse der Daten beschränkt.
	Einerseits ist dies unserer Erfahrung nach (und Einträgen in Internetforen, \ldots) die 
	meistgenutzte Art die Repräsentation in der Praxis zu bewerten. Zusätzlich bietet die Wahl der 
	Datensätze eine gute Gelegenheit die Repräsentationen visuell zu bewerten. 


%----------------------------------------------------------------------------------------

\section{Cartoon Set} 
\label{cartoonset}
	In diesem Abschnitt werden wir den \textit{Cartoon Set} Datensatz analysieren \cite{cartoon}. 
	Dabei werden wir:
	\begin{itemize}
		\item sehen, dass UMAP eine vergleichbare Laufzeit mit der von FIT-SNE hat
		\item das Verhalten der niedrigdimensionalen Darstellung unter verschiedenen 
			  Hyperparametern betrachten
		\item eine exemplarische Beschreibung der Hyperparameter geben
		\item UMAP mit anderen Dimensionsreduktionsverfahren vergleichen
		\item sehen, dass UMAP zugrundeliegende Mannigfaltigkeiten erkennt und darstellt
	\end{itemize}

	%-----------------------------------

	\subsection*{Beschreibung des Datensatzes}
	Der Cartoon Datensatz enthält \num{100000} unterschiedliche Bilder von gezeichneten Gesichtern 
	(siehe Abbildung \ref{fig:Cartoon_Sample}). 

	\begin{figure}
		%\centering
		\includegraphics[width=400px, height=73px]{Figures/Cartoon_Sample}
		%\decoRule
		\caption[Ausschnitt des Cartoon Set]{Sechs zufällig gewählte Gesichter des Cartoon Set.}
		\label{fig:Cartoon_Sample}
	\end{figure}

	Die Bilder wurden aus 16 Komponenten zusammengesetzt (u.a. Gesichtsform, Gesichtsfarbe, Frisur, Haarfarbe), 
	dabei variiert die Anzahl der Möglichkeiten pro Komponente zwischen zwei (Augenlid, Wimpern,\dots) und 
	111 (Anzahl mögliche Frisuren). 
	Die Farben der Komponenten wurden aus einem diskreten RGB Raum gewählt. Insgesamt ergibt sich eine mögliche 
	Anzahl von $10^{13}$ Gesichtern.

	Für die Analyse haben wir verschiedene Eigenschaften zusammengefasst um einen besseren Überblick zu haben. 
	Beispielsweise haben wir die 111 Frisuren, nach qualitativer Analyse, zu 19 Frisurformen zusammengefasst. 

	Wir haben uns für diesen Datensatz entschieden um UMAP auf Daten mit einer komplexeren Struktur zu testen 
	als dies in \cite{UMAP} gemacht wird. Dabei ist auch zu beachten, dass es aufgrund der 16 Komponenten aus 
	welchen die Gesichter bestehen kein richtige oder falsche Einbettung der Daten gibt. 

	Wir haben die Bewertung der Einbettung unter der Annahme gemacht, dass \textit{ähnliche} Gesichter 
	\textit{ähnliche} Hautfarben, Frisuren, Haarfarben, Brillen und Bärte haben. Diese fünf Eigenschaften 
	möchten wir besonders hervorheben, da sie die dominantesten Merkmale des Gesichts beschreiben.

	Die ursprüngliche Größe eines Bildes betrug $500 \times 500$ Pixel mit vier Farbkanälen 
	(CYMK-Darstellung der Farben). Aufgrund des großen Randes haben wir uns dazu entschieden die Größe der 
	Bilder auf $300 \times 300$ ohne nennenswerten Informationsverlust zu verringern. Weiterhin haben wir uns 
	für die Bewertung der Einbettung auf \num{10000} Bilder beschränkt. % TODO: Bewertung für 100000 samples?
	Somit beträgt die Dimension 
	des Cartoon Set $D = \num{360000}$ und die Anzahl an Beispielen $N = \num{100000}$.

	% Histogram über Verteilung der Frisuren

	% unterschiedliche n_components (range(15))

	% gute ergebnisse wegen aaprox kNN und lokaler Zusammenhang

	% Erwähne hohe Umbegungsdimension

	%-----------------------------------

	\subsection*{Qualitative Analyse der Ergebnisse}
		% Globale Struktur sehr gut erhalten und lokale auch, wenig abhängig von Parametern


		\begin{figure}
			%\centering
			\includegraphics[width=400px, height=278px]{Figures/umap_10k_vs_50k}
			%\decoRule
			\caption[UMAP auf 50k und 10k Daten]{TODO: Beschreibung des Bildes}
			\label{fig:umap_10k_vs_50k}
		\end{figure}


%----------------------------------------------------------------------------------------

\section{MNIST}
	% Lokal gut Einbettung vergleichbar mit anderen Verfahren
	% variiere set_opt_mix

%----------------------------------------------------------------------------------------

\subsection*{FMNIST}
	% Fließender Übergang zwischen Clustern, "Fehler" sind begründet

%----------------------------------------------------------------------------------------

\section{Laufzeitanalyse}
	Die praktischen Tests der Verfahren wurden auf Rechnern mit einer Linux-Architektur ausgeführt. 
	Die CPU Tests haben wir auf Intel Xeon 6136 CPUs mit 48 Kernen und 384 GB RAM ausgeführt. 
	Für die Verfahren welche mittels Berechnungen auf einer Graphikkarte verbessert wurden, haben 
	wir Intel Xeon Gold 6136 CPUs mit 188 GB RAM und Nvidia V100 GPUs genutzt. 
	Insgesamt haben wir über 100 Experimente gemacht um genauere Aussagen über die Laufzeit der Verfahren 
	zu treffen und diese in Abhängigkeit der wichtigen Parameter zu setzen.

%----------------------------------------------------------------------------------------

\section{Stabilität unter sub-sampling}
	% Siehe 5.2 von UMAP

%----------------------------------------------------------------------------------------

\section{Zusammenfassung der Ergebnisse}


