%!TEX root = ../main.tex

\chapter{Experimente} 

\label{Experimente}

%----------------------------------------------------------------------------------------

% A U F B A U
	% Welche Verfahren
	% Welche Daten
	% Welche Ergebnisse unter welchen Parametern
	% Welche Laufzeit
	% Welche Schlussfolgerungen

	% N O T I Z E N
	% Cartoonset, MNIST, (WIND)
	% PCA, UMAP, t-SNE, LargeVis

	% Test transform function

	% Google News für n_samples Dimension

	% Outlier, add completly different images 

	% Erwähne analytische Bewertungen der Einbettungen
	% trustworthiness-continuity (Kaski et al., 2003)
	% mean (smoothed) precision-recall (Venna et al., 2010)
	% nearest-neighbor accuracy (Van Der Maaten et al., 2009)

	% Stabilität der Ergebnisse

	% Komplett neue Gesichter

	% Cluster on FMNIST, Scores on MNIST (Costfunction and SVD)

	% Auswirkung von sampling auf kleinen Datensätzen

	% T E X T B A U S T E I N E
	% 'Empirisches testen der Hypothesen/ Annahmen'
	% 'UMAP auf realen/echten Daten'
	% In \cite{UMAP} wurde bereits die Stabilität des Verfahrens getestet.
	% Insbesondere verweisen wir auf Abbildung 3,4 in Abschnitt 5.
	% Die Stabilität des UMAP Verfahrens ist 

	% Mehr Datenpunkte, dann höhere perplexität für gleichen Ausgang, ähnlich zu n_neighbor
	% tSNE vergrößert Regionen mit höherer Dichte

	% Bei cartoonpca784 bleibt 99,842% der Varianz erhalten.
	% Bei cartoonpca10k weniger als 10^-5 * 2 verlust der Varianz 

	% Um eine gute Interpretation der Daten zu geben ist es wichtig ein sehr gutes Verständnis 
	% der Datensätze zu besitzen, deshalb haben wir uns auf leicht interpretierbare Daten beschränkt

	% Verweise auf Daten und erwähne deutlich feinere Struktur von UMAP
	% https://www.biorxiv.org/content/biorxiv/early/2018/04/10/298430.full.pdf

	% Keine Wordembeddings, da die Vorvererbeitung sehr wichtig ist.

%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------

% \section{Einleitung}
	Nach ausführlicher Darstellung der Theorie des UMAP Verfahrens, möchten wir nun UMAP auf 
	drei Datensätzen mit alternativen Verfahren empirisch testen.
	Wir werden eine möglichst vollständige Darstellung der Ergebnisse in dieser Arbeit präsentieren. 
	Allerdings ist es zu empfehlen die Ergebnisse in einem interaktiven Jupyter notebook zu betrachten. 
	Dieses befindet sich auf der beigelegten CD oder auf GitHub
	\footnote{\url{https://github.com/reinerschristopher/bachelorthesis}}. %!!! TODO: korrigiere link
 	
 	% TODO: schreibe Aufbau

%----------------------------------------------------------------------------------------

\section{Alternative Verfahren} \label{sec:verfahren}
	Wir haben uns dazu entschieden UMAP mit t-SNE, TriMap und PCA zu vergleichen. Die ersten beiden 
	Verfahren sollen kurz eingeführt werden, wobei wir insbesondere die wichtigen Hyperparameter der 
	Verfahren angeben. Eine Kenntnis des PCA Verfahrens setzen wir voraus. 
	An dieser Stelle ist zu bemerken, dass in den letzten Jahren zahlreiche neue DR Verfahren entwickelt wurden. 
	Aufgrund dessen können wir in dieser Arbeit nur eine kleine Teilmenge der DR Verfahren betrachten. 
	Ein sehr ausführlicher Vergleich findet sich in \cite{Maaten2008}. %, dieser berücksichtigt allerdings keine neueren Verfahren, da er 2008 publiziert wurde. 


	Da die Implementierungen des Laplacian Eigenmaps Verfahrens und Isomap Verfahrens schlecht für große 
	Datensätze skalieren, haben wir uns bewusst dazu entschieden, diese nicht mit in die Analyse aufzunehmen. 

	%-----------------------------------

	\subsection{t-SNE}
	% TODO: wichtige Terme einfügen?
	Das t-SNE Verfahren \cite{tSNE} ist zur Zeit eines der bekanntesten und meistgenutzten 
	nicht-linearen Dimensionsreduktionsverfahren. Dabei wird t-SNE fast ausschließlich 
	zur Visualisierung genutzt, da die Laufzeit für höhere Einbettungsdimensionen schlecht ist. 
	% TODO: Wie wir später sehen werden. (oder unten?)

	t-SNE konstruiert zuerst eine Wahrscheinlichkeitsverteilung $P$ auf Paaren $(i, j)$ der hochdimensionalen 
	Datenpunkten. Diese ist so gewählt, dass Paare ähnlicher Objekte eine höhere Wahrscheinlichkeit 
	zugeordnet bekommen, wohingegen sehr unterschiedliche Datenpunkte eine Wahrscheinlichkeit nahe $0$ haben. 
	Die Ähnlichkeit der Punkte wird dabei meist mittels der euklidischen Distanz gemessen, 
	kann aber ähnlich wie im UMAP Algorithmus durch andere Metriken ersetzt werden. Um $P$ zu konstruieren 
	wird eine Gaußverteilung genutzt, wobei die Varianz abhängig vom \code{perplexity} Parameter ist. 
	Die so erhaltenen Wahrscheinlichkeiten $p_{i | j}$ sind im Allgemeinen nicht symmetrisch. 
	Die Symmetrie wird durch mitteln der Daten erhalten. 

	Ähnlich wird eine Wahrscheinlichkeitsverteilung $Q$ im niedrigdimensionalen Raum mithilfe der 
	studentschen t-Verteilung konstruiert. Ursprünglich wurde $Q$ ebenfalls durch eine Gausverteilung 
	konstruiert, das so erhaltene Verfahren (SNE \cite{tSNEvar1}) ist allerdings aufgrund einer 
	schwierig zu optimierenden Zielfunktion und dem \enquote{crowding problem} wenig praktikabel.

	Um die d-dimensionale Repräsentation der Daten zu optimieren wir die Kullback-Leiber Divergenz 
	von zwischen $P$ und $Q$ bezüglich der $y_i$ minimiert. % TODO: werden y_i in Einleitung erwähnt?

	Seit der Veröffentlichung des Verfahrens wurden zahlreiche Verbesserungen, 
	insbesondere für die Laufzeit, vorgeschlagen \cite{tSNEmod1,tSNEmod3}. 
	Dabei ist besonders Barnes-Hut-SNE \cite{tSNEmod2} zu erwähnen, allerdings sollte hier beachtet werden, 
	dass aufgrund der Konstruktion einer speziellen Datenstruktur die Laufzeit für $d>3$ sehr schlecht ist.

	Die von t-SNE produzierte Repräsentation der Daten ist vom \code{perplexity} Parameter abhängig. 
	Dabei kann man festhalten, je größer die \code{perplexity} ist, desto größer ist die Varianz  % TODO: Verweise auf die Gleichungen oben 
	des Gaußverteilung. Somit werden für große \code{perplexity} Werte globalere Strukturen erfasst, 
	da der Gaußkern sehr breit ist. Wenn der \code{perplexity} Parameter in der Größenordnung der 
	Anzahl an Datenpunkten $N$ liegt gleicht t-SNE dem MDS Verfahren. % TODO: Referenz? 

	Der zweite wichtige Hyperparameter, welchen wir beschreiben möchten ist die \code{exaggeration}.
	meistens wird hier zwischen \code{early-} und \code{late-exaggeration} unterschieden. 
	Im wesentlichen verbessert der Parameter die Optimierung des Gradienten und sorgt dafür, 
	dass Punkte desselben Clusters möglichst schnell in der niedrigdimensionalen Repräsentation 
	gruppiert werden \cite{tSNEcluster}. Der \code{late-exaggeration} wie in \cite{tSNEmod3} 
	beschrieben kontrahiert gefundene Cluster, so lassen sich in einer 2- oder 3-dimensionalen 
	Darstellung leichter Cluster bestimmen - entweder visuell oder mittels Clustering-Verfahren. 

	Wir werden reale Datensätze analysieren und das Verhalten der Hyperparameter beschreiben, um 
	ein zusätzliches Verständnis für die von t-SNE genutzten Hyperparameter zu bekommen 
	empfiehlt sich \cite{tSNEparam}, dort werden interaktiv auf künstlich erzeugten Datensätzen 
	die Auswirkung der Parameter gezeigt.

	Für unsere Experimente haben wir die scikit Implementierung des t-SNE Verfahren genutzt \cite{scikit-learn}.
	Zusätzlich haben wir die openTSNE \cite{opentSNE} Implementierung genutzt. Diese beschleunigt 
	die Laufzeit des t-SNE Algorithmus durch eine zusätzliche Fouriertransformation \cite{tSNEmod3}.
	Die openTSNE Implementierung besitzt im Vergleich zur scikit Implementierung die Möglichkeit 
	den \code{late-exaggeration} Parameter zu spezifizieren. % TODO: später sehen wir die 

	Um einen Laufzeitvergleich mit der GPU Implementierung des UMAP Verfahrens zu ermöglichen, 
	werden wir eine GPU Implementierung von t-SNE betrachten \cite{tSNEGPUcode}. 
	Eine Beschreibung findet sich in \cite{tSNEGPUpaper}.

	%-----------------------------------

	\subsection{TriMap}
	Das TriMap Verfahren \cite{TriMap} soll eine globalere Repräsentation der Daten finden als 
	beispielsweise t-SNE, da nicht nur paarweise die Ähnlichkeit zweier Objekte $i, j$ betrachtet wird, 
	sondern stets Triple $i, j, k$. Die so erhaltene globale Struktur der Daten soll die 
	Cluster-Abstände der Daten repräsentieren. Die von uns gewählte Implementierung des Verfahrens findet 
	sich in \cite{trimapcode}.

	% TODO: TriMap besser beschreiben. 

	Wir haben diesem Algorithmus gewühlt, da die Tripletts Ähnlichkeiten mit 2-Simplizes des UMAP Verfahren haben.
	Die Tripletts sind vergleichbar mit den 2-Simplizes des UMAP Verfahrens. 
	Insbesondere können die Ansätze eine lineare Teilmenge ($O(N)$) an Tripletts zu finden 
	weitere Entwicklungen des UMAP Verfahren motivieren.

%----------------------------------------------------------------------------------------

% TODO: !!! Komplett überarbeiten
\section{Bewertung der Ergebnisse} \label{sec:bwertung}
	Um die $d$-dimensionalen Repräsentationen der Daten zu bewerten gibt es verschiedene Ansätze. 
	Diese sollen nun vorgestellt und verglichen werden. % !!TODO: entweder scores ergänzen oder text ändern

	Ein DR-Verfahren, welches die statistischen Eigenschaften der zugrundeliegenden Daten erfasst, 
	sollte invariant bezüglich Rauschen der Daten sein. Hingegen sollte eine schlechte Einbettung 
	wenig stabil sein, wenn zusätzliches Rauschen in den Daten auftritt. % TODO: Score angeben

	In \cite{Harmeling} werden zwei Methoden zur Auswahl eines geeigneten DR-Verfahrens verglichen. 

	Um die lokale Qualität der Algorithmen zu analysieren haben wir uns die \textit{Cluster} in der 
	$2$-dimensionalen Repräsentation angeschaut, wobei wir als Cluster eine Teilmenge der Daten bezeichnen, 
	welche deutlich von den anderen Datenpunkten getrennt ist. % TODO: 'Stetigkeit' innerhalb der Cluster?
	Insbesondere bei der Analyse des Cartoon Set \ref{sec:cartoonset} konnten wir gut lokale Strukturen 
	erkennen, da jeder Datenpunkt mehrere Eigenschaften gegeben hat -- im Vergleich zum MNIST und FMNIST 
	Datensatz, wo uns nur ein \textit{Label} pro Datenpunkt gegeben ist. 

	Die globale Struktur der Repräsentation qualitativ zu bewerten ist subjektiv. Dabei ist insbesondere 
	die Frage -- \enquote{Wie \textit{stark} unterscheiden sich die Cluster?} -- zu beantworten. 

	Für die qualitative Analyse wird die Fähigkeit des Gehirns genutzt Strukturen zu erkennen. 
	Nachteile der qualitativen Analyse sind, (1) die Subjektivität und somit Abhängigkeit vom Betrachter, 
	(2) dass sie nur im $d$-dimensionalen $(d \leq 3)$ möglich ist. 
	% und (3) die Problematik, dass es (noch) keine mathematische Formulierung der Bewertung gibt.

	In den folgenden Experimenten haben wir uns auf eine qualitative Analyse der Daten beschränkt.
	Einerseits ist dies unserer Erfahrung nach (und Einträgen in Internetforen, \ldots) die 
	meistgenutzte Art die Repräsentation in der Praxis zu bewerten. Zusätzlich bietet die Wahl der 
	Datensätze eine gute Gelegenheit die Repräsentationen visuell zu bewerten. 

%----------------------------------------------------------------------------------------

\section{Cartoon Set} \label{sec:cartoonset}
	In diesem Abschnitt werden wir den \textit{Cartoon Set} Datensatz analysieren \cite{cartoon}. 
	Dabei werden wir:
	\begin{itemize}
		\item sehen, dass UMAP eine vergleichbare Laufzeit mit der von FIT-SNE hat
		\item das Verhalten der niedrigdimensionalen Darstellung unter verschiedenen 
			  Hyperparametern betrachten
		\item eine exemplarische Beschreibung der Hyperparameter geben
		\item UMAP mit anderen Dimensionsreduktionsverfahren vergleichen
		\item sehen, dass UMAP zugrundeliegende Mannigfaltigkeiten erkennt und darstellt
	\end{itemize}

	%-----------------------------------

	\subsection*{Beschreibung des Datensatzes}
	Der Cartoon Datensatz enthält \num{100000} unterschiedliche Bilder von gezeichneten Gesichtern 
	(siehe Abbildung \ref{fig:Cartoon_Sample}). 

	\begin{figure}
		%\centering
		\includegraphics[width=400px, height=73px]{Figures/Cartoon_Sample}
		%\decoRule
		\caption[Ausschnitt des Cartoon Set]{Sechs zufällig gewählte Gesichter des Cartoon Set.}
		\label{fig:Cartoon_Sample}
	\end{figure}

	Die Bilder wurden aus 16 Labels zusammengesetzt (u.a. Gesichtsform, Gesichtsfarbe, Frisur, Haarfarbe), 
	dabei variiert die Anzahl der Möglichkeiten pro Label zwischen zwei (Augenlid, Wimpern,\dots) und 
	111 (Anzahl mögliche Frisuren). Die Farben der Komponenten wurden aus einem diskreten RGB Raum gewählt. 
	Insgesamt ergibt sich eine mögliche Anzahl von $10^{13}$ Gesichtern. Für die Analyse haben wir verschiedene 
	Eigenschaften zusammengefasst um einen besseren Überblick zu haben. 
	Beispielsweise haben wir die 111 Frisuren, nach qualitativer Analyse, zu 19 Frisurformen zusammengefasst. 

	Die ursprüngliche Größe eines Bildes betrug $500 \times 500$ Pixel mit vier Farbkanälen 
	(CYMK-Darstellung der Farben). Aufgrund des großen Randes haben wir uns dazu entschieden die Größe der 
	Bilder auf $300 \times 300$ ohne nennenswerten Informationsverlust zu verringern. Somit beträgt die Dimension 
	des Cartoon Set $D = \num{360000}$ und die Anzahl an Beispielen $N$ variiert zwischen $\num{10000}$ und $\num{100000}$.

	Wir haben uns für diesen Datensatz entschieden um UMAP auf Daten mit einer komplexeren Struktur zu testen 
	als dies in \cite{UMAP} gemacht wird. Dabei ist auch zu beachten, dass aufgrund der 16 Labels aus 
	welchen die Gesichter bestehen, die Qualität einer Einbettung schwieriger zu beurteilen ist als beispielsweise 
	im MNIST Datensatz (siehe Abschnitt \ref{sec:MNIST}). Wir haben die Bewertung der Einbettung unter der Annahme 
	gemacht, dass \textit{ähnliche} Gesichter \textit{ähnliche} Hautfarben, Frisuren, Haarfarben, Brillen und Bärte 
	besitzen. Diese fünf Eigenschaften möchten wir besonders hervorheben, da sie die dominantesten Merkmale des Gesichts 
	beschreiben. Somit werden wir eine Einbettung des Cartoon Set als \textit{gut} bewerten, wenn sie zwischen 
	diesen fünf Merkmalen unterscheidet.

	% Histogram über Verteilung der Frisuren

	% unterschiedliche n_components (range(15))

	% gute ergebnisse wegen aaprox kNN und lokaler Zusammenhang

	% Erwähne hohe Umbegungsdimension

	%-----------------------------------

	\subsection*{Qualitative Analyse der Ergebnisse}
		% Globale Struktur sehr gut erhalten und lokale auch, wenig abhängig von Parametern


	\begin{figure} % PCA als Startwert, global sind hair, face_color und hair_color, nicht faicial_hair und glasses
		%\centering
		\includegraphics[width=400px, height=200px]{Figures/pca_cartoon}
		%\decoRule
		\caption[PCA auf Cartoon Set]{PCA auf dem Cartoon Set, mit $N=\num{50000}, D=\num{360000}$. 
									Dabei sind die Punkte bezüglich der folgenden Attribute gekennzeichnet (v.l.n.r): Frisurtyp, Gesichtsfarbe, Haarfarbe.}
		\label{fig:pca_cartoon}
	\end{figure}

	\begin{figure} % Globale struktur der Punkte in den Verfahren. cmap=nhair
		%\centering
		\includegraphics[width=400px, height=131px]{Figures/cartoon_cluster}
		%\decoRule
		\caption[Cluster des Cartoon Set]{(v.l.n.r) UMAP, t-SNE, TriMap auf dem Cartoon Set, mit $N=\num{10000}, D=\num{360000}$. 
										Dabei entsprechen die Punkte des blauen Gebiets dem oberen Drittel der PCA Einbettung, 
										das gelbe Gebiet dem unteren Drittel der PCA Einbettung und die Punkte außerhalb eines Gebietes dem mittleren Teil der PCA Einbettung}
		\label{fig:cartoon_cluster}
	\end{figure}

	\begin{figure} % Lokale struktur der Punkte in den Verfahren. cmap=nhair_color and cmap=nface_color. übergänge in TriMap fließender, tSNE weniger gehäuft/dicht als umap
		%\centering
		\includegraphics[width=400px, height=272px]{Figures/cartoon_local}
		%\decoRule
		\caption[Cluster des Cartoon Set]{(v.l.n.r) UMAP, t-SNE, TriMap auf dem Cartoon Set, mit $N=\num{10000}, D=\num{360000}$. 
										blablabla}
		\label{fig:cartoon_local}
	\end{figure}

	\begin{figure} % Lokale struktur der Punkte in den Verfahren, cluster sehr ähnlich. cmap=nhair_color
		%\centering
		\includegraphics[width=400px, height=134px]{Figures/cartoon_local_local}
		%\decoRule
		\caption[Cluster des Cartoon Set]{(v.l.n.r) UMAP, t-SNE, TriMap auf dem Cartoon Set, mit $N=\num{10000}, D=\num{360000}$. 
										blablabla}
		\label{fig:cartoon_local_local}
	\end{figure}

	\begin{figure}
		%\centering
		\includegraphics[width=400px, height=278px]{Figures/umap_10k_vs_50k}
		%\decoRule
		\caption[UMAP auf 50k und 10k Daten]{TODO: Beschreibung des Bildes}
		\label{fig:umap_10k_vs_50k}
	\end{figure}



%----------------------------------------------------------------------------------------

\section{MNIST} \label{sec:MNIST}
	% Lokal gut Einbettung vergleichbar mit anderen Verfahren
	% variiere set_opt_mix
	% Beispielsweise sollten die Cluster welche die Ziffern 1 und 7 darstellen näher zueinander liegen als die Cluster der Ziffern 1 und 6. 
%----------------------------------------------------------------------------------------

\section*{FMNIST} \label{sec:FMNIST}
	% Fließender Übergang zwischen Clustern, "Fehler" sind begründet

%----------------------------------------------------------------------------------------

\section{Laufzeitanalyse} \label{sec:runtime}
	Die praktischen Tests der Verfahren wurden auf Rechnern mit einer Linux-Architektur ausgeführt. 
	Die CPU Tests haben wir auf Intel Xeon 6136 CPUs mit 48 Kernen und 384 GB RAM ausgeführt. 
	Für die Verfahren welche mittels Berechnungen auf einer Graphikkarte verbessert wurden, haben 
	wir Intel Xeon Gold 6136 CPUs mit 188 GB RAM und Nvidia V100 GPUs genutzt. 
	Insgesamt haben wir über 100 Experimente gemacht um genauere Aussagen über die Laufzeit der Verfahren 
	zu treffen und diese in Abhängigkeit der wichtigen Parameter zu setzen.

%----------------------------------------------------------------------------------------

\section{Zusammenfassung der Ergebnisse}
	Die Ergebnisse haben gezeigt, dass alle drei verwendeten DR Verfahren lokale Strukturen der 
	Bilddatensätze erkannt haben. 

%----------------------------------------------------------------------------------------